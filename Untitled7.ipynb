{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110e681e-2bce-45bc-8395-5dd9a41d5cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44 images\n",
      "Video dimensions: 1024x557\n",
      "Processing image 1/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_1.png\n",
      "Processing image 2/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_1001.png\n",
      "Processing image 3/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_2001.png\n",
      "Processing image 4/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_3001.png\n",
      "Processing image 5/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_4001.png\n",
      "Processing image 6/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_5001.png\n",
      "Processing image 7/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_6001.png\n",
      "Processing image 8/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_7001.png\n",
      "Processing image 9/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_8001.png\n",
      "Processing image 10/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_9001.png\n",
      "Processing image 11/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_10001.png\n",
      "Processing image 12/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_11001.png\n",
      "Processing image 13/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_12001.png\n",
      "Processing image 14/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_13001.png\n",
      "Processing image 15/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_14001.png\n",
      "Processing image 16/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_15001.png\n",
      "Processing image 17/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_16001.png\n",
      "Processing image 18/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_17001.png\n",
      "Processing image 19/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_18001.png\n",
      "Processing image 20/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_19001.png\n",
      "Processing image 21/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_20001.png\n",
      "Processing image 22/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_21001.png\n",
      "Processing image 23/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_22001.png\n",
      "Processing image 24/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_23001.png\n",
      "Processing image 25/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_24001.png\n",
      "Processing image 26/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_25001.png\n",
      "Processing image 27/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_26001.png\n",
      "Processing image 28/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_27001.png\n",
      "Processing image 29/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_28001.png\n",
      "Processing image 30/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_29001.png\n",
      "Processing image 31/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_30001.png\n",
      "Processing image 32/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_31001.png\n",
      "Processing image 33/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_32001.png\n",
      "Processing image 34/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_33001.png\n",
      "Processing image 35/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_34001.png\n",
      "Processing image 36/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_35001.png\n",
      "Processing image 37/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_36001.png\n",
      "Processing image 38/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_37001.png\n",
      "Processing image 39/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_38001.png\n",
      "Processing image 40/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_39001.png\n",
      "Processing image 41/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_40001.png\n",
      "Processing image 42/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_41001.png\n",
      "Processing image 43/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_42001.png\n",
      "Processing image 44/44: experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_43001.png\n",
      "Video saved as: output_slow.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def create_video_from_images(input_folder, output_video, fps=30, duration_per_image=None):\n",
    "    \"\"\"\n",
    "    Create a video from a sequence of images.\n",
    "    \n",
    "    Args:\n",
    "        input_folder: Path to folder containing images\n",
    "        output_video: Output video file path\n",
    "        fps: Frames per second for the output video\n",
    "        duration_per_image: How long each image should be displayed (in seconds)\n",
    "                          If None, each image is shown for 1 frame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get list of image files (steps 1 to 43)\n",
    "    image_files = []\n",
    "    for i in range(0, 44):  # 1 to 43 inclusive\n",
    "        img_path = f\"experiments/ft_lora_proper_inpaint_task_face/fixed_test_4_step_{i*1000+1}.png\"\n",
    "        if os.path.exists(img_path):\n",
    "            image_files.append(img_path)\n",
    "        else:\n",
    "            \n",
    "            print(f\"Warning: {img_path} not found, skipping...\")\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No images found!\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images\")\n",
    "    \n",
    "    # Read the first image to get dimensions\n",
    "    first_image = cv2.imread(image_files[0])\n",
    "    if first_image is None:\n",
    "        print(f\"Could not read first image: {image_files[0]}\")\n",
    "        return False\n",
    "    \n",
    "    height, width, layers = first_image.shape\n",
    "    print(f\"Video dimensions: {width}x{height}\")\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can also use 'XVID'\n",
    "    video_writer = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "    \n",
    "    if not video_writer.isOpened():\n",
    "        print(\"Error: Could not open video writer\")\n",
    "        return False\n",
    "    \n",
    "    # Calculate how many frames each image should appear\n",
    "    frames_per_image = 1\n",
    "    if duration_per_image:\n",
    "        frames_per_image = int(fps * duration_per_image)\n",
    "    \n",
    "    # Process each image\n",
    "    for i, img_path in enumerate(image_files):\n",
    "        print(f\"Processing image {i+1}/{len(image_files)}: {img_path}\")\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read {img_path}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Resize image if needed (to match first image dimensions)\n",
    "        if img.shape[:2] != (height, width):\n",
    "            img = cv2.resize(img, (width, height))\n",
    "        \n",
    "        # Write the frame(s) to video\n",
    "        for _ in range(frames_per_image):\n",
    "            video_writer.write(img)\n",
    "    \n",
    "    # Release the video writer\n",
    "    video_writer.release()\n",
    "    \n",
    "    print(f\"Video saved as: {output_video}\")\n",
    "    return True\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Basic usage - each image shown for 1 frame at 30fps (very fast slideshow)\n",
    "    \n",
    "    # Slower version - each image shown for 0.5 seconds\n",
    "    create_video_from_images(\n",
    "        input_folder=\"experiments/ft_lora_proper_inpaint_task_face/\",\n",
    "        output_video=\"output_slow.mp4\",\n",
    "        fps=30,\n",
    "        duration_per_image=0.1\n",
    "    )\n",
    "    \n",
    "    # # Very slow version - each image shown for 2 seconds\n",
    "    # create_video_from_images(\n",
    "    #     input_folder=\"experiments/ft_lora_proper_inpaint_task_face/\",\n",
    "    #     output_video=\"output_very_slow.mp4\",\n",
    "    #     fps=30,\n",
    "    #     duration_per_image=2.0\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17b3ff-b7a5-4459-b2b3-7a3afe75fba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d8ed7c-d651-48a0-b772-870e96c8241c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4645a035-87b4-4205-958d-e2904782bc55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
